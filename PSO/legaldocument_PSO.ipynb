{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-13T11:27:24.179823200Z",
     "start_time": "2024-11-13T11:27:23.475850300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('../corpus.txt', 'r') as file:\n",
    "    # Read the lines from the file and store them in a list\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Optionally, you can remove newline characters from each line\n",
    "corpus = [line.strip() for line in corpus]\n",
    "\n",
    "\n",
    "\n",
    "query = \"Somebody breached our contract and caused financial loss. What legal actions can we take?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 most relevant legal documents for your issue:\n",
      "Document 45: Section 2302, Health Law: Regulates healthcare financing, including insurance and public programs. Subsection 2302.1 defines the Affordable Care Act and its implementation. Subsection 2302.2 outlines eligibility for public health programs like Medicaid.\n",
      "Document 0: Section 101, Contract Law: Governs contract formation requirements, including offer, acceptance, and consideration. Subsection 101.1 details enforceable contract types. Subsection 101.2 addresses remedies for breach, specifying compensatory, punitive, and nominal damages.\n",
      "Document 31: Section 1602, International Law: Deals with international dispute resolution mechanisms. Subsection 1602.1 discusses arbitration and mediation. Subsection 1602.2 provides guidelines for state-to-state legal proceedings.\n",
      "\n",
      "Mean Reciprocal Rank (MRR): 0.00\n",
      "Mean Average Precision (MAP): 0.00\n"
     ]
    }
   ],
   "source": [
    "# Sample Legal document corpus\n",
    "legal_documents = corpus\n",
    "\n",
    "# User's issue as input query\n",
    "user_issue = query\n",
    "\n",
    "# Fine-tuned TF-IDF Vectorizer for document-query similarity\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.85, stop_words='english')\n",
    "combined_corpus = legal_documents + [user_issue]\n",
    "combined_tfidf_matrix = vectorizer.fit_transform(combined_corpus)\n",
    "\n",
    "document_tfidf_matrix = combined_tfidf_matrix[:-1]\n",
    "query_tfidf_matrix = combined_tfidf_matrix[-1]\n",
    "\n",
    "similarity_scores = cosine_similarity(document_tfidf_matrix, query_tfidf_matrix).flatten()\n",
    "\n",
    "# PSO Parameters\n",
    "num_particles = 10\n",
    "num_iterations = 20\n",
    "top_k = 3\n",
    "\n",
    "# Initialize particles and velocities\n",
    "particles = [random.sample(range(len(legal_documents)), top_k) for _ in range(num_particles)]\n",
    "velocities = [random.sample(range(len(legal_documents)), top_k) for _ in range(num_particles)]\n",
    "\n",
    "# Initialize best positions and scores\n",
    "particle_best_positions = particles.copy()\n",
    "particle_best_scores = [sum(similarity_scores[particle]) for particle in particles]\n",
    "\n",
    "# Initialize global best\n",
    "global_best_position = particle_best_positions[np.argmax(particle_best_scores)]\n",
    "global_best_score = max(particle_best_scores)\n",
    "\n",
    "# PSO Parameters\n",
    "w = 0.5  # Inertia weight\n",
    "c1 = 1.5  # Cognitive component\n",
    "c2 = 2.0  # Social component\n",
    "\n",
    "def update_velocity(velocity, particle, best_position, global_best_position):\n",
    "    new_velocity = velocity.copy()\n",
    "    for i in range(len(velocity)):\n",
    "        if random.random() < 0.5:\n",
    "            new_velocity[i] = best_position[i]\n",
    "        else:\n",
    "            new_velocity[i] = global_best_position[i]\n",
    "    return new_velocity\n",
    "\n",
    "def update_position(particle, velocity):\n",
    "    new_particle = particle.copy()\n",
    "    for i in range(len(velocity)):\n",
    "        if velocity[i] not in new_particle:\n",
    "            new_particle[i] = velocity[i]\n",
    "    return new_particle\n",
    "\n",
    "# PSO Algorithm\n",
    "for iteration in range(num_iterations):\n",
    "    for i in range(num_particles):\n",
    "        # Update velocity and position\n",
    "        velocities[i] = update_velocity(velocities[i], particles[i], particle_best_positions[i], global_best_position)\n",
    "        particles[i] = update_position(particles[i], velocities[i])\n",
    "\n",
    "        # Calculate fitness score\n",
    "        current_score = sum(similarity_scores[particles[i]])\n",
    "\n",
    "        # Update personal and global best\n",
    "        if current_score > particle_best_scores[i]:\n",
    "            particle_best_positions[i] = particles[i]\n",
    "            particle_best_scores[i] = current_score\n",
    "\n",
    "        if current_score > global_best_score:\n",
    "            global_best_position = particles[i]\n",
    "            global_best_score = current_score\n",
    "\n",
    "# Output the most relevant legal documents for the user's issue\n",
    "print(f\"\\nTop {top_k} most relevant legal documents for your issue:\")\n",
    "for idx in global_best_position:\n",
    "    print(f\"Document {idx}: {legal_documents[idx]}\")\n",
    "\n",
    "# Performance Metrics Calculation\n",
    "\n",
    "# Define a relevance threshold to consider a document relevant\n",
    "relevance_threshold = 0.15929\n",
    "\n",
    "# Rank documents by similarity score\n",
    "ranked_indices = np.argsort(similarity_scores)[::-1]  # Indices sorted in descending order of similarity scores\n",
    "ranked_scores = similarity_scores[ranked_indices]     # Corresponding similarity scores in descending order\n",
    "\n",
    "# Determine relevance based on the similarity threshold\n",
    "relevance_labels = [1 if score >= relevance_threshold else 0 for score in ranked_scores]\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR)\n",
    "def mean_reciprocal_rank(relevance_labels):\n",
    "    for rank, label in enumerate(relevance_labels, start=1):\n",
    "        if label == 1:  # First relevant document\n",
    "            return 1 / rank\n",
    "    return 0  # No relevant document found\n",
    "\n",
    "mrr = mean_reciprocal_rank(relevance_labels)\n",
    "print(f\"\\nMean Reciprocal Rank (MRR): {mrr:.2f}\")\n",
    "\n",
    "# Calculate Mean Average Precision (MAP)\n",
    "def mean_average_precision(relevance_labels):\n",
    "    relevant_docs = 0\n",
    "    cumulative_precision = 0\n",
    "    for rank, label in enumerate(relevance_labels, start=1):\n",
    "        if label == 1:\n",
    "            relevant_docs += 1\n",
    "            cumulative_precision += relevant_docs / rank\n",
    "    return cumulative_precision / relevant_docs if relevant_docs > 0 else 0\n",
    "\n",
    "map_score = mean_average_precision(relevance_labels)\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T11:27:24.258757200Z",
     "start_time": "2024-11-13T11:27:24.179823200Z"
    }
   },
   "id": "900f56eba6af3555"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
