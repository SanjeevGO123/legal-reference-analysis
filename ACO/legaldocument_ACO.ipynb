{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-13T11:26:21.301228300Z",
     "start_time": "2024-11-13T11:26:20.537351100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('../corpus.txt', 'r') as file:\n",
    "    # Read the lines from the file and store them in a list\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Optionally, you can remove newline characters from each line\n",
    "corpus = [line.strip() for line in corpus]\n",
    "\n",
    "\n",
    "\n",
    "query = \"Somebody breached our contract and caused financial loss. What legal actions can we take?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 most relevant legal documents for your issue:\n",
      "Document 51: Section 2602, Contract Law: Regulates breach of contract, including damages and remedies. Subsection 2602.1 defines compensatory damages, punitive damages, and nominal damages. Subsection 2602.2 outlines remedies for breach of contract in commercial transactions.\n",
      "Document 50: Section 2601, Contract Law: Defines contracts related to sales and services. Subsection 2601.1 outlines general contract formation and validity. Subsection 2601.2 specifies terms for service contracts and the rights of the parties involved.\n",
      "Document 27: Section 1402, Consumer Protection Law: Discusses debt collection practices, financial disclosures, and lending standards. Subsection 1402.1 mandates clear communication of loan terms. Subsection 1402.2 provides protections against predatory lending.\n",
      "\n",
      "Mean Reciprocal Rank (MRR): 0.00\n",
      "Mean Average Precision (MAP): 0.00\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Legal document corpus\n",
    "legal_documents = corpus\n",
    "\n",
    "# Step 2: User's issue as input query\n",
    "user_issue = query\n",
    "\n",
    "# Step 3: Fine-tuned TF-IDF Vectorizer for document-query similarity\n",
    "# Creating a combined vectorizer for documents and query\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.85, stop_words='english')\n",
    "combined_corpus = legal_documents + [user_issue]\n",
    "combined_tfidf_matrix = vectorizer.fit_transform(combined_corpus)\n",
    "\n",
    "# Separate TF-IDF matrices for documents and query\n",
    "document_tfidf_matrix = combined_tfidf_matrix[:-1]  # All but the last element (documents)\n",
    "query_tfidf_matrix = combined_tfidf_matrix[-1]  # The last element (query)\n",
    "\n",
    "# Calculate cosine similarity between each document and the query\n",
    "similarity_scores = cosine_similarity(document_tfidf_matrix, query_tfidf_matrix).flatten()\n",
    "\n",
    "# Step 4: Create a distance matrix for ACO (1 - similarity scores)\n",
    "distance_matrix = 1 - similarity_scores\n",
    "num_documents = len(legal_documents)\n",
    "\n",
    "# ACO Parameters\n",
    "num_ants = 5\n",
    "num_iterations = 20\n",
    "alpha = 1  # Pheromone importance\n",
    "beta = 3  # Distance importance increased for more sensitivity to similarity\n",
    "evaporation_rate = 0.2\n",
    "pheromone_deposit = 50\n",
    "top_k = 3  # Number of relevant documents to retrieve\n",
    "\n",
    "# Initialize pheromone levels\n",
    "pheromone_matrix = np.ones(num_documents) / num_documents\n",
    "\n",
    "# Function to choose the next document based on probabilities\n",
    "def choose_next_document(pheromones, distances, alpha, beta):\n",
    "    pheromone_factor = pheromones ** alpha\n",
    "    distance_factor = (1 / distances) ** beta\n",
    "    probabilities = pheromone_factor * distance_factor\n",
    "    probabilities /= probabilities.sum()\n",
    "    return np.random.choice(range(len(legal_documents)), p=probabilities)\n",
    "\n",
    "# Function to update pheromone levels\n",
    "def update_pheromones(pheromones, documents_visited, evaporation_rate, pheromone_deposit):\n",
    "    pheromones *= (1 - evaporation_rate)  # Evaporate pheromones\n",
    "    for document in documents_visited:\n",
    "        pheromones[document] += pheromone_deposit  # Add pheromone to visited documents\n",
    "\n",
    "# ACO Algorithm for document retrieval\n",
    "def ant_colony_optimization(num_iterations, num_ants, distance_matrix, pheromone_matrix, alpha, beta, evaporation_rate, pheromone_deposit, top_k):\n",
    "    best_documents = set()\n",
    "    best_similarities = []\n",
    "    for iteration in range(num_iterations):\n",
    "        ant_paths = []\n",
    "        ant_similarities = []\n",
    "        for ant in range(num_ants):\n",
    "            current_path = []\n",
    "            current_similarity = 0\n",
    "            for _ in range(top_k):  # Select top_k documents per ant\n",
    "                current_document = choose_next_document(pheromone_matrix, distance_matrix, alpha, beta)\n",
    "                current_similarity += similarity_scores[current_document]\n",
    "                current_path.append(current_document)\n",
    "            # Save the chosen documents and their total similarity\n",
    "            ant_paths.append(current_path)\n",
    "            ant_similarities.append(current_similarity)\n",
    "        # Update pheromones for all documents visited by all ants\n",
    "        for path in ant_paths:\n",
    "            update_pheromones(pheromone_matrix, path, evaporation_rate, pheromone_deposit)\n",
    "        # Keep track of the best paths (relevant documents)\n",
    "        for i in range(len(ant_paths)):\n",
    "            if len(best_similarities) < top_k or ant_similarities[i] > min(best_similarities):\n",
    "                best_documents.update(ant_paths[i])\n",
    "                best_similarities.append(ant_similarities[i])\n",
    "    # Sort and return the top K most relevant documents\n",
    "    sorted_best_documents = sorted(best_documents, key=lambda x: similarity_scores[x], reverse=True)\n",
    "    return sorted_best_documents[:top_k]\n",
    "\n",
    "# Run the ACO algorithm to find the top K relevant documents\n",
    "best_documents_indices = ant_colony_optimization(num_iterations, num_ants, distance_matrix, pheromone_matrix, alpha, beta, evaporation_rate, pheromone_deposit, top_k)\n",
    "\n",
    "# Output the most relevant legal documents for the user's issue\n",
    "print(f\"\\nTop {top_k} most relevant legal documents for your issue:\")\n",
    "for idx in best_documents_indices:\n",
    "    print(f\"Document {idx}: {legal_documents[idx]}\")\n",
    "\n",
    "# Performance Metrics Calculation\n",
    "\n",
    "# Define a similarity threshold to consider a document relevant\n",
    "relevance_threshold = 0.15929\n",
    "\n",
    "# Rank documents by similarity score\n",
    "ranked_indices = np.argsort(similarity_scores)[::-1]  # Indices sorted in descending order of similarity scores\n",
    "ranked_scores = similarity_scores[ranked_indices]     # Corresponding similarity scores in descending order\n",
    "\n",
    "# Determine relevance based on the similarity threshold\n",
    "relevance_labels = [1 if score >= relevance_threshold else 0 for score in ranked_scores]\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR)\n",
    "def mean_reciprocal_rank(relevance_labels):\n",
    "    for rank, label in enumerate(relevance_labels, start=1):\n",
    "        if label == 1:  # First relevant document\n",
    "            return 1 / rank\n",
    "    return 0  # No relevant document found\n",
    "\n",
    "mrr = mean_reciprocal_rank(relevance_labels)\n",
    "print(f\"\\nMean Reciprocal Rank (MRR): {mrr:.2f}\")\n",
    "\n",
    "# Calculate Mean Average Precision (MAP)\n",
    "def mean_average_precision(relevance_labels):\n",
    "    relevant_docs = 0\n",
    "    cumulative_precision = 0\n",
    "    for rank, label in enumerate(relevance_labels, start=1):\n",
    "        if label == 1:\n",
    "            relevant_docs += 1\n",
    "            cumulative_precision += relevant_docs / rank\n",
    "    return cumulative_precision / relevant_docs if relevant_docs > 0 else 0\n",
    "\n",
    "map_score = mean_average_precision(relevance_labels)\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T11:26:21.345514600Z",
     "start_time": "2024-11-13T11:26:21.301228300Z"
    }
   },
   "id": "815e71259334ccc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
